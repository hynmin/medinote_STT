"""
STT ê´€ë¦¬ í‰ê°€ ì§€í‘œ ê³„ì‚° (í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ìš©)

ì£¼ìš” ê¸°ëŠ¥:
- compute_stt_metrics: Whisper ê²°ê³¼ ê¸°ë°˜ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
- Confidence Score: Whisper ì‹ ë¢°ë„
- Audio Quality: ì˜¤ë””ì˜¤ í’ˆì§ˆ (ë¬´ìŒ, RMS, í´ë¦¬í•‘)
- Word Count: ë‹¨ì–´ ìˆ˜
"""
import numpy as np
from typing import Dict, List, Any
import librosa


def compute_stt_metrics(
    audio_path: str,
    whisper_output: Dict[str, Any],
    text: str
) -> Dict[str, float]:
    """
    STT ê´€ë¦¬ ì§€í‘œ ê³„ì‚°

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        whisper_output: Whisper ì›ë³¸ ì¶œë ¥ (segments í¬í•¨)
        text: ë³€í™˜ëœ í…ìŠ¤íŠ¸

    Returns:
        ê´€ë¦¬ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    metrics = {}

    # 1. Confidence Score (Whisper ì‹ ë¢°ë„)
    confidence_metrics = _compute_confidence(whisper_output)
    metrics.update(confidence_metrics)

    # 2. Audio Quality (ì˜¤ë””ì˜¤ í’ˆì§ˆ)
    audio_metrics = _compute_audio_quality(audio_path)
    metrics.update(audio_metrics)

    # 3. ë‹¨ì–´ ìˆ˜ë§Œ ê³„ì‚° (ë°˜ë³µ/í™˜ì²­ ì§€í‘œ ì œê±°)
    metrics["word_count"] = len(text.split())

    return metrics


def _compute_confidence(whisper_output: Dict[str, Any]) -> Dict[str, float]:
    """
    Whisper ì‹ ë¢°ë„ ì§€í‘œ ê³„ì‚°

    Returns:
        - avg_confidence: í‰ê·  ì‹ ë¢°ë„
        - min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        - low_confidence_ratio: ë‚®ì€ ì‹ ë¢°ë„ ë¹„ìœ¨ (< 0.7)
    """
    segments = whisper_output.get("segments", [])

    if not segments:
        return {
            "avg_confidence": 0.0,
            "min_confidence": 0.0,
            "low_confidence_ratio": 1.0
        }

    # ê° segmentì˜ confidence ì¶”ì¶œ (avg_logprob ì‚¬ìš©)
    confidences = []
    for seg in segments:
        # avg_logprobì„ í™•ë¥ ë¡œ ë³€í™˜ (ëŒ€ëµì )
        # avg_logprobì€ ë³´í†µ -1.0 ~ 0.0 ë²”ìœ„
        logprob = seg.get("avg_logprob", -1.0)
        # ê°„ë‹¨í•œ ë³€í™˜: exp(logprob) ì‚¬ìš©
        confidence = np.exp(logprob)
        confidences.append(confidence)

    avg_conf = float(np.mean(confidences))
    min_conf = float(np.min(confidences))
    low_conf_count = sum(1 for c in confidences if c < 0.7)
    low_conf_ratio = low_conf_count / len(confidences) if confidences else 0.0

    return {
        "avg_confidence": avg_conf,
        "min_confidence": min_conf,
        "low_confidence_ratio": low_conf_ratio
    }


def _compute_audio_quality(audio_path: str) -> Dict[str, float]:
    """
    ì˜¤ë””ì˜¤ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°

    Returns:
        - silence_ratio: ë¬´ìŒ ë¹„ìœ¨
        - audio_rms_energy: RMS ì—ë„ˆì§€ (SNR ëŒ€ìš©)
        - clipping_detected: í´ë¦¬í•‘ ê°ì§€ (0 or 1)
    """
    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(audio_path, sr=None)

        # ë¬´ìŒ ë¹„ìœ¨ ê³„ì‚°
        rms = librosa.feature.rms(y=y)[0]
        silence_threshold = 0.01
        silence_frames = np.sum(rms < silence_threshold)
        silence_ratio = silence_frames / len(rms) if len(rms) > 0 else 0.0

        # RMS ì—ë„ˆì§€ ê³„ì‚°
        audio_rms_energy = float(np.sqrt(np.mean(y**2)))

        # í´ë¦¬í•‘ ê°ì§€ (ì ˆëŒ€ê°’ì´ 0.99 ì´ìƒì¸ ìƒ˜í”Œ)
        clipping_threshold = 0.99
        clipping_samples = np.sum(np.abs(y) > clipping_threshold)
        clipping_detected = 1 if clipping_samples > len(y) * 0.001 else 0  # 0.1% ì´ìƒì´ë©´ í´ë¦¬í•‘

        return {
            "silence_ratio": float(silence_ratio),
            "audio_rms_energy": audio_rms_energy,
            "clipping_detected": clipping_detected
        }

    except Exception as e:
        print(f"âš ï¸ Audio quality calculation failed: {e}")
        return {
            "silence_ratio": 0.0,
            "audio_rms_energy": 0.0,
            "clipping_detected": 0
        }


# ì´ì „ ë°˜ë³µ ì ìˆ˜, í™˜ì²­ ìœ„í—˜ë„ ê³„ì‚° í•¨ìˆ˜ ì œê±°ë¨


# Example usage
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ
    whisper_output = {
        "segments": [
            {"avg_logprob": -0.3, "text": "ì•ˆë…•í•˜ì„¸ìš”"},
            {"avg_logprob": -0.5, "text": "ì–´ë””ê°€ ë¶ˆí¸í•˜ì„¸ìš”"},
        ]
    }

    metrics = compute_stt_metrics(
        audio_path="data/audio/test.mp3",
        whisper_output=whisper_output,
        text="ì•ˆë…•í•˜ì„¸ìš” ì–´ë””ê°€ ë¶ˆí¸í•˜ì„¸ìš”"
    )

    print("\nğŸ“Š STT Metrics:")
    for key, value in metrics.items():
        print(f"  {key}: {value:.4f}")
